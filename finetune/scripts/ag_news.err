Generating train split: 0 examples [00:00, ? examples/s]Generating train split: 60000 examples [00:00, 526428.81 examples/s]Generating train split: 84000 examples [00:00, 531012.58 examples/s]
Generating validation split: 0 examples [00:00, ? examples/s]Generating validation split: 12000 examples [00:00, 494387.84 examples/s]
Generating test split: 0 examples [00:00, ? examples/s]Generating test split: 12000 examples [00:00, 511812.57 examples/s]
/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
Map:   0%|          | 0/84000 [00:00<?, ? examples/s]Map: 100%|██████████| 84000/84000 [00:15<00:00, 5484.32 examples/s]Map: 100%|██████████| 84000/84000 [00:15<00:00, 5439.49 examples/s]
Map:   0%|          | 0/12000 [00:00<?, ? examples/s]Map: 100%|██████████| 12000/12000 [00:01<00:00, 6506.27 examples/s]Map: 100%|██████████| 12000/12000 [00:01<00:00, 6444.81 examples/s]
Map:   0%|          | 0/12000 [00:00<?, ? examples/s]Map: 100%|██████████| 12000/12000 [00:01<00:00, 6168.51 examples/s]Map: 100%|██████████| 12000/12000 [00:01<00:00, 6112.68 examples/s]
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python finetune_lora.py --lora_r 1 --lora_alpha 1 --lora_dr ...
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name     | Type                                | Params
-----------------------------------------------------------------
0 | model    | DistilBertForSequenceClassification | 67.0 M
1 | val_acc  | MulticlassAccuracy                  | 0     
2 | test_acc | MulticlassAccuracy                  | 0     
-----------------------------------------------------------------
85.3 K    Trainable params
67.0 M    Non-trainable params
67.0 M    Total params
268.167   Total estimated model params size (MB)
Traceback (most recent call last):
  File "/work/LAS/jannesar-lab/dphuong/fedtext/finetune/finetune_lora.py", line 224, in <module>
    trainer.fit(
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 44, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 987, in _run
    results = self._run_stage()
              ^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1031, in _run_stage
    self._run_sanity_check()
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/trainer.py", line 1060, in _run_sanity_check
    val_loop.run()
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/loops/utilities.py", line 182, in _decorator
    return loop_run(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 135, in run
    self._evaluation_step(batch, batch_idx, dataloader_idx, dataloader_iter)
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/loops/evaluation_loop.py", line 396, in _evaluation_step
    output = call._call_strategy_hook(trainer, hook_name, *step_args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/trainer/call.py", line 309, in _call_strategy_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/lightning/pytorch/strategies/strategy.py", line 412, in validation_step
    return self.lightning_module.validation_step(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/fedtext/finetune/local_model_utilities.py", line 85, in validation_step
    self.val_acc(predicted_labels, batch["label"])
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1532, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torch/nn/modules/module.py", line 1541, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torchmetrics/metric.py", line 311, in forward
    self._forward_cache = self._forward_reduce_state_update(*args, **kwargs)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torchmetrics/metric.py", line 380, in _forward_reduce_state_update
    self.update(*args, **kwargs)
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torchmetrics/metric.py", line 492, in wrapped_func
    raise err
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torchmetrics/metric.py", line 482, in wrapped_func
    update(*args, **kwargs)
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torchmetrics/classification/stat_scores.py", line 339, in update
    _multiclass_stat_scores_tensor_validation(
  File "/work/LAS/jannesar-lab/dphuong/.conda/envs/flora_pronto/lib/python3.12/site-packages/torchmetrics/functional/classification/stat_scores.py", line 319, in _multiclass_stat_scores_tensor_validation
    raise RuntimeError(
RuntimeError: Detected more unique values in `target` than expected. Expected only 2 but found 4 in `target`.

real	0m30.060s
user	0m33.370s
sys	0m5.430s
