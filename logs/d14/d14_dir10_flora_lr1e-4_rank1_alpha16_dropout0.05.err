Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/home/jpmunoz/AutoML/Phuong/fedtext/system/main.py", line 455, in <module>
    run(args)
  File "/home/jpmunoz/AutoML/Phuong/fedtext/system/main.py", line 142, in run
    server = FLora(args, i)
             ^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext/system/flcore/servers/serverlora.py", line 56, in __init__
    self.set_clients(clientLORA)
  File "/home/jpmunoz/AutoML/Phuong/fedtext/system/flcore/servers/serverlora.py", line 79, in set_clients
    client = clientObj(self.args, 
             ^^^^^^^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext/system/flcore/clients/clientlora.py", line 56, in __init__
    self.model_object = DistilBertModelWithLoRA(model_id=args.model_id, home_dir=args.home_dir, lora_params=self.lora_params, num_labels=self.num_labels).to(args.device)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext/system/flcore/trainmodel/distilbert_model.py", line 117, in __init__
    self.model = AutoModelForSequenceClassification.from_pretrained(self.model_id, num_labels=self.num_labels)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 3754, in from_pretrained
    ) = cls._load_pretrained_model(
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 4162, in _load_pretrained_model
    error_msgs = _load_state_dict_into_model(model_to_load, state_dict, start_prefix)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 703, in _load_state_dict_into_model
    load(model_to_load, state_dict, prefix=start_prefix)
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 701, in load
    load(child, state_dict, prefix + name + ".")
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 701, in load
    load(child, state_dict, prefix + name + ".")
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 701, in load
    load(child, state_dict, prefix + name + ".")
  [Previous line repeated 3 more times]
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/transformers/modeling_utils.py", line 697, in load
    module._load_from_state_dict(*args)
  File "/home/jpmunoz/AutoML/Phuong/fedtext_env/lib/python3.11/site-packages/torch/nn/modules/module.py", line 2075, in _load_from_state_dict
    param.copy_(input_param)
KeyboardInterrupt
